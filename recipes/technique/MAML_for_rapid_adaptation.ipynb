{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Meta-Learning for Rapid Adaptation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we'll explore multi-agent meta-learning, a technique that allows MARL systems to quickly adapt to new tasks or environments. This is particularly relevant for app modernization, where agents might need to adapt to different codebases or infrastructure setups.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing MAML for MARL\n",
    "\n",
    "We'll implement a simplified version of Model-Agnostic Meta-Learning (MAML) for multi-agent systems using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAMLAgent(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MAMLAgent, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class MAML:\n",
    "    def __init__(self, agent, alpha=0.01, beta=0.001):\n",
    "        self.agent = agent\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.meta_optimizer = optim.Adam(self.agent.parameters(), lr=beta)\n",
    "    \n",
    "    def adapt(self, task_data, num_steps=1):\n",
    "        adapted_agent = type(self.agent)(self.agent.fc1.in_features, self.agent.fc3.out_features)\n",
    "        adapted_agent.load_state_dict(self.agent.state_dict())\n",
    "        optimizer = optim.SGD(adapted_agent.parameters(), lr=self.alpha)\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            loss = self.compute_loss(adapted_agent, task_data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        return adapted_agent\n",
    "    \n",
    "    def meta_update(self, task_batch):\n",
    "        meta_loss = 0\n",
    "        for task_data in task_batch:\n",
    "            adapted_agent = self.adapt(task_data)\n",
    "            meta_loss += self.compute_loss(adapted_agent, task_data)\n",
    "        \n",
    "        self.meta_optimizer.zero_grad()\n",
    "        meta_loss.backward()\n",
    "        self.meta_optimizer.step()\n",
    "        \n",
    "        return meta_loss.item()\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_loss(agent, data):\n",
    "        # Simplified loss computation\n",
    "        inputs, targets = data\n",
    "        outputs = agent(inputs)\n",
    "        return nn.MSELoss()(outputs, targets)\n",
    "\n",
    "# Helper function to generate task data\n",
    "def generate_task_data(num_samples, input_dim, output_dim):\n",
    "    inputs = torch.randn(num_samples, input_dim)\n",
    "    weights = torch.randn(input_dim, output_dim)\n",
    "    targets = torch.matmul(inputs, weights) + torch.randn(num_samples, output_dim) * 0.1\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Meta-Learner\n",
    "\n",
    "Now, let's train our MAML agent on a distribution of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Meta Loss: 1008.2819\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m     12\u001b[0m     task_batch \u001b[38;5;241m=\u001b[39m [generate_task_data(num_samples_per_task, input_dim, output_dim) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tasks)]\n\u001b[0;32m---> 13\u001b[0m     meta_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     meta_losses\u001b[38;5;241m.\u001b[39mappend(meta_loss)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m, in \u001b[0;36mMAML.meta_update\u001b[0;34m(self, task_batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m meta_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task_data \u001b[38;5;129;01min\u001b[39;00m task_batch:\n\u001b[0;32m---> 36\u001b[0m     adapted_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     meta_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(adapted_agent, task_data)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m, in \u001b[0;36mMAML.adapt\u001b[0;34m(self, task_data, num_steps)\u001b[0m\n\u001b[1;32m     26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(adapted_agent, task_data)\n\u001b[1;32m     27\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adapted_agent\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = 10\n",
    "output_dim = 5\n",
    "num_tasks = 100\n",
    "num_samples_per_task = 20\n",
    "\n",
    "agent = MAMLAgent(input_dim, output_dim)\n",
    "maml = MAML(agent)\n",
    "\n",
    "meta_losses = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    task_batch = [generate_task_data(num_samples_per_task, input_dim, output_dim) for _ in range(num_tasks)]\n",
    "    meta_loss = maml.meta_update(task_batch)\n",
    "    meta_losses.append(meta_loss)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Meta Loss: {meta_loss:.4f}\")\n",
    "\n",
    "plt.plot(meta_losses)\n",
    "plt.title(\"Meta-Learning Progress\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Meta Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Rapid Adaptation\n",
    "\n",
    "Let's test our meta-learned agent's ability to quickly adapt to new tasks and compare it to a non-meta-learned baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_adaptation(maml_agent, baseline_agent, new_task_data, num_adaptation_steps):\n",
    "    maml_losses = []\n",
    "    baseline_losses = []\n",
    "    \n",
    "    # Adapt MAML agent\n",
    "    adapted_maml_agent = maml.adapt(new_task_data, num_adaptation_steps)\n",
    "    \n",
    "    # Train baseline agent from scratch\n",
    "    baseline_optimizer = optim.SGD(baseline_agent.parameters(), lr=maml.alpha)\n",
    "    \n",
    "    for step in range(num_adaptation_steps):\n",
    "        # Evaluate MAML agent\n",
    "        maml_loss = maml.compute_loss(adapted_maml_agent, new_task_data)\n",
    "        maml_losses.append(maml_loss.item())\n",
    "        \n",
    "        # Evaluate and update baseline agent\n",
    "        baseline_loss = maml.compute_loss(baseline_agent, new_task_data)\n",
    "        baseline_losses.append(baseline_loss.item())\n",
    "        \n",
    "        baseline_optimizer.zero_grad()\n",
    "        baseline_loss.backward()\n",
    "        baseline_optimizer.step()\n",
    "    \n",
    "    return maml_losses, baseline_losses\n",
    "\n",
    "# Generate a new task\n",
    "new_task_data = generate_task_data(num_samples_per_task, input_dim, output_dim)\n",
    "\n",
    "# Create a new baseline agent\n",
    "baseline_agent = MAMLAgent(input_dim, output_dim)\n",
    "\n",
    "# Evaluate adaptation\n",
    "num_adaptation_steps = 50\n",
    "maml_losses, baseline_losses = evaluate_adaptation(maml.agent, baseline_agent, new_task_data, num_adaptation_steps)\n",
    "\n",
    "plt.plot(maml_losses, label=\"MAML\")\n",
    "plt.plot(baseline_losses, label=\"Baseline\")\n",
    "plt.title(\"Adaptation to New Task\")\n",
    "plt.xlabel(\"Adaptation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we implemented a simple version of MAML for multi-agent systems and demonstrated its ability to quickly adapt to new tasks. This approach could be particularly useful in app modernization scenarios, where agents need to rapidly adjust to different codebases or infrastructure configurations.\n",
    "\n",
    "Some potential applications in app modernization include:\n",
    "1. Quickly adapting to different programming languages or frameworks\n",
    "2. Adjusting to various cloud infrastructure setups\n",
    "3. Generalizing modernization strategies across diverse application architectures\n",
    "\n",
    "In future work, we could extend this approach to more complex MARL scenarios and specific app modernization tasks.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Finn, C., Abbeel, P., & Levine, S. (2017). Model-agnostic meta-learning for fast adaptation of deep networks. ICML.\n",
    "2. Al-Shedivat, M., et al. (2017). Continuous adaptation via meta-learning in nonstationary and competitive environments. ICLR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
